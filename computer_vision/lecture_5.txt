lecture 5

image enhancement 
    (contrast, noise, sharpening)
    gray-level transformations
        s=T(r)
            where s and r and intensities after and before
            and T may be piecewise linear, negative, logarithm function 
        we use histograms that show the amount of certain intensities
            far to the right = high intensity 
            left = low intensity 
        redistribute grey-levelsb  
            increase contrast 
                we have information loss of high and low frequencies
            histogram equalization 
                redistribute gray-levels as evenly as possible - correspond to a brighmess distribution where all values are equally probable 
                assume gray levels are continous and have been normalized to between 0 and 1
                find a transformation T than maps gray values r in the input image to gray values s=T(r) in the transformed image 
                    since we don't increase or decrease, only redestribute, we can just move around the pixels → hence a map from inputpixel to outputpixel

spatial filtering
    filtering using spatial masks
    linear 
        types of linear filters 
            lowpass
                elimanates edges
                blur
            highpass
                eliminate low freq components like shadings
            bandpass
                eliminate outside a given frequency range 
                combination of above 
                common practice
        identify type of filter
            we have a filter kernel [1,0,-1]
            express in fourier domain 
                1. express filter in continous domain using Dirac functions 
                    h(x) = d(x)-d(x-2)
                2. get the fourier transform by exploiting the shifting property of Dirac functions 
                    ^h(w)=integral h(x)e^iwxdx
                    calculate the integral as they do in slide 17
                    try values x in h(x) between 0 and pi
                        find where values pass through 
    nonlinear 
        basic 
            low-pass Gaussian filter formula on page 24
                binomial kernels
                    we can use pascals triangle to get a kernel because it approximates a gaussian 
                        a gaussian does not lead to the same blocky patterns because it is isotropic (in all directions)
            mean filtering  aka. local spatial averaging
                we sum the average of the neighborhood
                problem: errors spread and a salt/pepper pixel can affect a lot of other pixels 
            
            isotropic filters 
                they work indipendent of the direction of the edge, rotating then filtering is same as filtering then rotating 
        types
            median filtering 
                eliminates local extreme (salt and pepper)
                creates painting-like images
            selective averaging 
            weighted averaging 
            Anisotropic smoothing with bilateral filtering
                Anisotropic smoothing
                    smooth differently in different directions, usually in order to preserve edges.
                idea: smooth pixels based on similarity s(x,n) between pixels 
                problem: impossible to do in frequency domain 
            autoencoder
                Network with layers that first reduces the image size (encoder), followed by layers that scale up to original size (decoder)
                Image enhancement with deep autoencoder
                    using network: scale down the image, then scale up the image 
            super-resolution with GANs 
                GAN
                    Generative adversarial networks 
                common autoencoders that are based on two networks trained in parallel 
                figuring out if an immage is upscaled or of high resolution      

differentiation operators 
    derivatives of images to find edges and stuff
        definitions 
            first order x-wise derivative operator 
                fx = f(x+1, y) - f(x,y)
                or more common in practice
                fx = 1/2(f(x+1, y)-f(x-1, y))
                    twice the size, forward and backwards, divided by 2
            second order x-wise derivative operator 
                fxx = f(x+1, y) + f(x-1, y) - 2f(x,y)
        gradient 
            <upside-down-triangle>f = (fx,fy)
            first order, linear, non-isotropic 
            gradient per definition takes into account the direction (hence non-isotropic) and it's linear
        gradient magnitude
            |<upside-down-triangle>f|=sqrt(f²x+f²y)
            first order, non-linear, isotropic 
            magnitude loses the info about direction (different unit, just a number) and also it's not linear because it changes direction at y=0
        laplacian 
            <upside-down-triangle>²f=fxx+fyy
            2nd order, linear, isotropic 
            depends only on the distance from the origin, not on the angle
            simplest possible laplacian operator:
                         0, 1, 0
                f(x,y) = 1,-4, 1
                         0, 1, 0
            what's the point?
                we have the original blurry image 
                we apply the laplacian operator and get a grayish image 
                we subtract the laplation from the original image and get a sharper image as the result 
                    looks a bit overexposed 


math 
    fourier transform of a derivative 
    proof on page 45
    F(fx(x))=iw^f(w)
        ^f(w)=F(f(x))


        
